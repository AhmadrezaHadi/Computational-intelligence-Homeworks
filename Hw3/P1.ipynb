{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06e018a-0fd4-4739-9085-257ea20e41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard PyTorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter # TensorBoard support\n",
    "\n",
    "# import torchvision module to handle image manipulation\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# calculate train time, writing train data to files etc.\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877fd25f-a323-4d23-909d-b01c557e3f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070 with Max-Q Design'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,), (0.5,),)])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.get_device_name(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd5b50e-3f48-42b3-921c-020c1da1daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.FashionMNIST('data', download=False, train=True, transform=transform)\n",
    "testset = datasets.FashionMNIST('data', download=False, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b4b602-4d62-4081-817e-a52943aa99c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e8cfdc1-254a-4f94-a70b-5b4273486182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the neural network, expand on top of nn.Module\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # define layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    # define forward function\n",
    "    def forward(self, t):\n",
    "        # conv 1\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # conv 2\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # fc1\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # fc2\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # output\n",
    "        t = self.out(t)\n",
    "        # don't need softmax here since we'll use cross-entropy as activation.\n",
    "\n",
    "        return t\n",
    "\n",
    "net = Network()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0146a46d-1e0e-4ad8-82b3-d23284df1378",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f96958a0-315d-4ec9-872c-00e0e3414b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    40] loss: 1.825\n",
      "[1,    80] loss: 0.863\n",
      "[1,   120] loss: 0.701\n",
      "[1,   160] loss: 0.665\n",
      "[1,   200] loss: 0.617\n",
      "[2,    40] loss: 0.554\n",
      "[2,    80] loss: 0.548\n",
      "[2,   120] loss: 0.546\n",
      "[2,   160] loss: 0.511\n",
      "[2,   200] loss: 0.480\n",
      "[3,    40] loss: 0.479\n",
      "[3,    80] loss: 0.463\n",
      "[3,   120] loss: 0.463\n",
      "[3,   160] loss: 0.452\n",
      "[3,   200] loss: 0.419\n",
      "[4,    40] loss: 0.418\n",
      "[4,    80] loss: 0.416\n",
      "[4,   120] loss: 0.419\n",
      "[4,   160] loss: 0.385\n",
      "[4,   200] loss: 0.383\n",
      "[5,    40] loss: 0.386\n",
      "[5,    80] loss: 0.379\n",
      "[5,   120] loss: 0.376\n",
      "[5,   160] loss: 0.373\n",
      "[5,   200] loss: 0.370\n",
      "[6,    40] loss: 0.355\n",
      "[6,    80] loss: 0.350\n",
      "[6,   120] loss: 0.356\n",
      "[6,   160] loss: 0.347\n",
      "[6,   200] loss: 0.354\n",
      "[7,    40] loss: 0.337\n",
      "[7,    80] loss: 0.328\n",
      "[7,   120] loss: 0.338\n",
      "[7,   160] loss: 0.350\n",
      "[7,   200] loss: 0.321\n",
      "[8,    40] loss: 0.332\n",
      "[8,    80] loss: 0.322\n",
      "[8,   120] loss: 0.325\n",
      "[8,   160] loss: 0.319\n",
      "[8,   200] loss: 0.316\n",
      "[9,    40] loss: 0.316\n",
      "[9,    80] loss: 0.300\n",
      "[9,   120] loss: 0.301\n",
      "[9,   160] loss: 0.295\n",
      "[9,   200] loss: 0.322\n",
      "[10,    40] loss: 0.304\n",
      "[10,    80] loss: 0.306\n",
      "[10,   120] loss: 0.299\n",
      "[10,   160] loss: 0.298\n",
      "[10,   200] loss: 0.294\n",
      "[11,    40] loss: 0.286\n",
      "[11,    80] loss: 0.296\n",
      "[11,   120] loss: 0.280\n",
      "[11,   160] loss: 0.297\n",
      "[11,   200] loss: 0.292\n",
      "[12,    40] loss: 0.272\n",
      "[12,    80] loss: 0.278\n",
      "[12,   120] loss: 0.279\n",
      "[12,   160] loss: 0.289\n",
      "[12,   200] loss: 0.281\n",
      "[13,    40] loss: 0.268\n",
      "[13,    80] loss: 0.267\n",
      "[13,   120] loss: 0.289\n",
      "[13,   160] loss: 0.271\n",
      "[13,   200] loss: 0.278\n",
      "[14,    40] loss: 0.257\n",
      "[14,    80] loss: 0.264\n",
      "[14,   120] loss: 0.270\n",
      "[14,   160] loss: 0.274\n",
      "[14,   200] loss: 0.269\n",
      "[15,    40] loss: 0.272\n",
      "[15,    80] loss: 0.261\n",
      "[15,   120] loss: 0.248\n",
      "[15,   160] loss: 0.260\n",
      "[15,   200] loss: 0.270\n",
      "[16,    40] loss: 0.254\n",
      "[16,    80] loss: 0.261\n",
      "[16,   120] loss: 0.263\n",
      "[16,   160] loss: 0.246\n",
      "[16,   200] loss: 0.245\n",
      "[17,    40] loss: 0.244\n",
      "[17,    80] loss: 0.249\n",
      "[17,   120] loss: 0.245\n",
      "[17,   160] loss: 0.255\n",
      "[17,   200] loss: 0.256\n",
      "[18,    40] loss: 0.243\n",
      "[18,    80] loss: 0.237\n",
      "[18,   120] loss: 0.249\n",
      "[18,   160] loss: 0.256\n",
      "[18,   200] loss: 0.248\n",
      "[19,    40] loss: 0.235\n",
      "[19,    80] loss: 0.237\n",
      "[19,   120] loss: 0.238\n",
      "[19,   160] loss: 0.244\n",
      "[19,   200] loss: 0.247\n",
      "[20,    40] loss: 0.230\n",
      "[20,    80] loss: 0.226\n",
      "[20,   120] loss: 0.240\n",
      "[20,   160] loss: 0.241\n",
      "[20,   200] loss: 0.234\n",
      "[21,    40] loss: 0.231\n",
      "[21,    80] loss: 0.229\n",
      "[21,   120] loss: 0.226\n",
      "[21,   160] loss: 0.233\n",
      "[21,   200] loss: 0.233\n",
      "[22,    40] loss: 0.218\n",
      "[22,    80] loss: 0.234\n",
      "[22,   120] loss: 0.230\n",
      "[22,   160] loss: 0.210\n",
      "[22,   200] loss: 0.243\n",
      "[23,    40] loss: 0.224\n",
      "[23,    80] loss: 0.218\n",
      "[23,   120] loss: 0.226\n",
      "[23,   160] loss: 0.220\n",
      "[23,   200] loss: 0.219\n",
      "[24,    40] loss: 0.211\n",
      "[24,    80] loss: 0.222\n",
      "[24,   120] loss: 0.221\n",
      "[24,   160] loss: 0.226\n",
      "[24,   200] loss: 0.210\n",
      "[25,    40] loss: 0.213\n",
      "[25,    80] loss: 0.209\n",
      "[25,   120] loss: 0.209\n",
      "[25,   160] loss: 0.218\n",
      "[25,   200] loss: 0.205\n",
      "[26,    40] loss: 0.202\n",
      "[26,    80] loss: 0.200\n",
      "[26,   120] loss: 0.209\n",
      "[26,   160] loss: 0.224\n",
      "[26,   200] loss: 0.207\n",
      "[27,    40] loss: 0.195\n",
      "[27,    80] loss: 0.210\n",
      "[27,   120] loss: 0.203\n",
      "[27,   160] loss: 0.203\n",
      "[27,   200] loss: 0.207\n",
      "[28,    40] loss: 0.198\n",
      "[28,    80] loss: 0.197\n",
      "[28,   120] loss: 0.209\n",
      "[28,   160] loss: 0.202\n",
      "[28,   200] loss: 0.211\n",
      "[29,    40] loss: 0.180\n",
      "[29,    80] loss: 0.196\n",
      "[29,   120] loss: 0.206\n",
      "[29,   160] loss: 0.196\n",
      "[29,   200] loss: 0.207\n",
      "[30,    40] loss: 0.186\n",
      "[30,    80] loss: 0.195\n",
      "[30,   120] loss: 0.200\n",
      "[30,   160] loss: 0.193\n",
      "[30,   200] loss: 0.199\n",
      "[31,    40] loss: 0.194\n",
      "[31,    80] loss: 0.183\n",
      "[31,   120] loss: 0.192\n",
      "[31,   160] loss: 0.190\n",
      "[31,   200] loss: 0.199\n",
      "[32,    40] loss: 0.192\n",
      "[32,    80] loss: 0.182\n",
      "[32,   120] loss: 0.195\n",
      "[32,   160] loss: 0.189\n",
      "[32,   200] loss: 0.190\n",
      "[33,    40] loss: 0.191\n",
      "[33,    80] loss: 0.191\n",
      "[33,   120] loss: 0.178\n",
      "[33,   160] loss: 0.185\n",
      "[33,   200] loss: 0.184\n",
      "[34,    40] loss: 0.180\n",
      "[34,    80] loss: 0.164\n",
      "[34,   120] loss: 0.190\n",
      "[34,   160] loss: 0.188\n",
      "[34,   200] loss: 0.187\n",
      "[35,    40] loss: 0.171\n",
      "[35,    80] loss: 0.180\n",
      "[35,   120] loss: 0.175\n",
      "[35,   160] loss: 0.176\n",
      "[35,   200] loss: 0.177\n",
      "[36,    40] loss: 0.167\n",
      "[36,    80] loss: 0.170\n",
      "[36,   120] loss: 0.184\n",
      "[36,   160] loss: 0.176\n",
      "[36,   200] loss: 0.168\n",
      "[37,    40] loss: 0.171\n",
      "[37,    80] loss: 0.166\n",
      "[37,   120] loss: 0.162\n",
      "[37,   160] loss: 0.189\n",
      "[37,   200] loss: 0.169\n",
      "[38,    40] loss: 0.157\n",
      "[38,    80] loss: 0.172\n",
      "[38,   120] loss: 0.163\n",
      "[38,   160] loss: 0.172\n",
      "[38,   200] loss: 0.171\n",
      "[39,    40] loss: 0.162\n",
      "[39,    80] loss: 0.154\n",
      "[39,   120] loss: 0.156\n",
      "[39,   160] loss: 0.181\n",
      "[39,   200] loss: 0.168\n",
      "[40,    40] loss: 0.161\n",
      "[40,    80] loss: 0.161\n",
      "[40,   120] loss: 0.161\n",
      "[40,   160] loss: 0.169\n",
      "[40,   200] loss: 0.161\n",
      "[41,    40] loss: 0.155\n",
      "[41,    80] loss: 0.156\n",
      "[41,   120] loss: 0.155\n",
      "[41,   160] loss: 0.157\n",
      "[41,   200] loss: 0.165\n",
      "[42,    40] loss: 0.149\n",
      "[42,    80] loss: 0.152\n",
      "[42,   120] loss: 0.142\n",
      "[42,   160] loss: 0.160\n",
      "[42,   200] loss: 0.159\n",
      "[43,    40] loss: 0.154\n",
      "[43,    80] loss: 0.158\n",
      "[43,   120] loss: 0.158\n",
      "[43,   160] loss: 0.148\n",
      "[43,   200] loss: 0.143\n",
      "[44,    40] loss: 0.150\n",
      "[44,    80] loss: 0.149\n",
      "[44,   120] loss: 0.150\n",
      "[44,   160] loss: 0.161\n",
      "[44,   200] loss: 0.157\n",
      "[45,    40] loss: 0.143\n",
      "[45,    80] loss: 0.145\n",
      "[45,   120] loss: 0.145\n",
      "[45,   160] loss: 0.135\n",
      "[45,   200] loss: 0.149\n",
      "[46,    40] loss: 0.139\n",
      "[46,    80] loss: 0.146\n",
      "[46,   120] loss: 0.142\n",
      "[46,   160] loss: 0.147\n",
      "[46,   200] loss: 0.144\n",
      "[47,    40] loss: 0.130\n",
      "[47,    80] loss: 0.130\n",
      "[47,   120] loss: 0.135\n",
      "[47,   160] loss: 0.150\n",
      "[47,   200] loss: 0.147\n",
      "[48,    40] loss: 0.129\n",
      "[48,    80] loss: 0.135\n",
      "[48,   120] loss: 0.130\n",
      "[48,   160] loss: 0.149\n",
      "[48,   200] loss: 0.148\n",
      "[49,    40] loss: 0.128\n",
      "[49,    80] loss: 0.142\n",
      "[49,   120] loss: 0.134\n",
      "[49,   160] loss: 0.134\n",
      "[49,   200] loss: 0.137\n",
      "[50,    40] loss: 0.134\n",
      "[50,    80] loss: 0.136\n",
      "[50,   120] loss: 0.131\n",
      "[50,   160] loss: 0.134\n",
      "[50,   200] loss: 0.139\n",
      "[51,    40] loss: 0.128\n",
      "[51,    80] loss: 0.125\n",
      "[51,   120] loss: 0.127\n",
      "[51,   160] loss: 0.128\n",
      "[51,   200] loss: 0.137\n",
      "[52,    40] loss: 0.119\n",
      "[52,    80] loss: 0.132\n",
      "[52,   120] loss: 0.128\n",
      "[52,   160] loss: 0.131\n",
      "[52,   200] loss: 0.134\n",
      "[53,    40] loss: 0.127\n",
      "[53,    80] loss: 0.119\n",
      "[53,   120] loss: 0.128\n",
      "[53,   160] loss: 0.123\n",
      "[53,   200] loss: 0.130\n",
      "[54,    40] loss: 0.120\n",
      "[54,    80] loss: 0.119\n",
      "[54,   120] loss: 0.122\n",
      "[54,   160] loss: 0.119\n",
      "[54,   200] loss: 0.133\n",
      "[55,    40] loss: 0.109\n",
      "[55,    80] loss: 0.119\n",
      "[55,   120] loss: 0.128\n",
      "[55,   160] loss: 0.117\n",
      "[55,   200] loss: 0.125\n",
      "[56,    40] loss: 0.114\n",
      "[56,    80] loss: 0.118\n",
      "[56,   120] loss: 0.106\n",
      "[56,   160] loss: 0.122\n",
      "[56,   200] loss: 0.118\n",
      "[57,    40] loss: 0.106\n",
      "[57,    80] loss: 0.113\n",
      "[57,   120] loss: 0.120\n",
      "[57,   160] loss: 0.111\n",
      "[57,   200] loss: 0.116\n",
      "[58,    40] loss: 0.108\n",
      "[58,    80] loss: 0.104\n",
      "[58,   120] loss: 0.119\n",
      "[58,   160] loss: 0.119\n",
      "[58,   200] loss: 0.116\n",
      "[59,    40] loss: 0.112\n",
      "[59,    80] loss: 0.108\n",
      "[59,   120] loss: 0.108\n",
      "[59,   160] loss: 0.109\n",
      "[59,   200] loss: 0.116\n",
      "[60,    40] loss: 0.116\n",
      "[60,    80] loss: 0.119\n",
      "[60,   120] loss: 0.112\n",
      "[60,   160] loss: 0.115\n",
      "[60,   200] loss: 0.103\n",
      "[61,    40] loss: 0.107\n",
      "[61,    80] loss: 0.110\n",
      "[61,   120] loss: 0.105\n",
      "[61,   160] loss: 0.101\n",
      "[61,   200] loss: 0.104\n",
      "[62,    40] loss: 0.097\n",
      "[62,    80] loss: 0.103\n",
      "[62,   120] loss: 0.101\n",
      "[62,   160] loss: 0.108\n",
      "[62,   200] loss: 0.108\n",
      "[63,    40] loss: 0.099\n",
      "[63,    80] loss: 0.091\n",
      "[63,   120] loss: 0.101\n",
      "[63,   160] loss: 0.108\n",
      "[63,   200] loss: 0.111\n",
      "[64,    40] loss: 0.109\n",
      "[64,    80] loss: 0.091\n",
      "[64,   120] loss: 0.104\n",
      "[64,   160] loss: 0.107\n",
      "[64,   200] loss: 0.099\n",
      "[65,    40] loss: 0.090\n",
      "[65,    80] loss: 0.104\n",
      "[65,   120] loss: 0.108\n",
      "[65,   160] loss: 0.109\n",
      "[65,   200] loss: 0.098\n",
      "[66,    40] loss: 0.092\n",
      "[66,    80] loss: 0.089\n",
      "[66,   120] loss: 0.096\n",
      "[66,   160] loss: 0.100\n",
      "[66,   200] loss: 0.100\n",
      "[67,    40] loss: 0.096\n",
      "[67,    80] loss: 0.086\n",
      "[67,   120] loss: 0.099\n",
      "[67,   160] loss: 0.101\n",
      "[67,   200] loss: 0.097\n",
      "[68,    40] loss: 0.089\n",
      "[68,    80] loss: 0.082\n",
      "[68,   120] loss: 0.089\n",
      "[68,   160] loss: 0.092\n",
      "[68,   200] loss: 0.096\n",
      "[69,    40] loss: 0.083\n",
      "[69,    80] loss: 0.083\n",
      "[69,   120] loss: 0.091\n",
      "[69,   160] loss: 0.093\n",
      "[69,   200] loss: 0.096\n",
      "[70,    40] loss: 0.090\n",
      "[70,    80] loss: 0.099\n",
      "[70,   120] loss: 0.091\n",
      "[70,   160] loss: 0.098\n",
      "[70,   200] loss: 0.094\n",
      "[71,    40] loss: 0.083\n",
      "[71,    80] loss: 0.082\n",
      "[71,   120] loss: 0.086\n",
      "[71,   160] loss: 0.092\n",
      "[71,   200] loss: 0.100\n",
      "[72,    40] loss: 0.089\n",
      "[72,    80] loss: 0.081\n",
      "[72,   120] loss: 0.089\n",
      "[72,   160] loss: 0.088\n",
      "[72,   200] loss: 0.084\n",
      "[73,    40] loss: 0.071\n",
      "[73,    80] loss: 0.081\n",
      "[73,   120] loss: 0.080\n",
      "[73,   160] loss: 0.079\n",
      "[73,   200] loss: 0.079\n",
      "[74,    40] loss: 0.076\n",
      "[74,    80] loss: 0.082\n",
      "[74,   120] loss: 0.078\n",
      "[74,   160] loss: 0.081\n",
      "[74,   200] loss: 0.086\n",
      "[75,    40] loss: 0.080\n",
      "[75,    80] loss: 0.077\n",
      "[75,   120] loss: 0.080\n",
      "[75,   160] loss: 0.090\n",
      "[75,   200] loss: 0.090\n",
      "[76,    40] loss: 0.076\n",
      "[76,    80] loss: 0.067\n",
      "[76,   120] loss: 0.073\n",
      "[76,   160] loss: 0.079\n",
      "[76,   200] loss: 0.089\n",
      "[77,    40] loss: 0.073\n",
      "[77,    80] loss: 0.078\n",
      "[77,   120] loss: 0.079\n",
      "[77,   160] loss: 0.073\n",
      "[77,   200] loss: 0.077\n",
      "[78,    40] loss: 0.071\n",
      "[78,    80] loss: 0.073\n",
      "[78,   120] loss: 0.075\n",
      "[78,   160] loss: 0.087\n",
      "[78,   200] loss: 0.088\n",
      "[79,    40] loss: 0.072\n",
      "[79,    80] loss: 0.075\n",
      "[79,   120] loss: 0.074\n",
      "[79,   160] loss: 0.072\n",
      "[79,   200] loss: 0.072\n",
      "[80,    40] loss: 0.067\n",
      "[80,    80] loss: 0.064\n",
      "[80,   120] loss: 0.073\n",
      "[80,   160] loss: 0.082\n",
      "[80,   200] loss: 0.078\n",
      "[81,    40] loss: 0.064\n",
      "[81,    80] loss: 0.068\n",
      "[81,   120] loss: 0.070\n",
      "[81,   160] loss: 0.078\n",
      "[81,   200] loss: 0.072\n",
      "[82,    40] loss: 0.064\n",
      "[82,    80] loss: 0.071\n",
      "[82,   120] loss: 0.068\n",
      "[82,   160] loss: 0.067\n",
      "[82,   200] loss: 0.080\n",
      "[83,    40] loss: 0.063\n",
      "[83,    80] loss: 0.067\n",
      "[83,   120] loss: 0.068\n",
      "[83,   160] loss: 0.069\n",
      "[83,   200] loss: 0.088\n",
      "[84,    40] loss: 0.061\n",
      "[84,    80] loss: 0.065\n",
      "[84,   120] loss: 0.067\n",
      "[84,   160] loss: 0.063\n",
      "[84,   200] loss: 0.075\n",
      "[85,    40] loss: 0.062\n",
      "[85,    80] loss: 0.061\n",
      "[85,   120] loss: 0.071\n",
      "[85,   160] loss: 0.061\n",
      "[85,   200] loss: 0.073\n",
      "[86,    40] loss: 0.067\n",
      "[86,    80] loss: 0.067\n",
      "[86,   120] loss: 0.066\n",
      "[86,   160] loss: 0.063\n",
      "[86,   200] loss: 0.067\n",
      "[87,    40] loss: 0.066\n",
      "[87,    80] loss: 0.059\n",
      "[87,   120] loss: 0.063\n",
      "[87,   160] loss: 0.064\n",
      "[87,   200] loss: 0.074\n",
      "[88,    40] loss: 0.055\n",
      "[88,    80] loss: 0.068\n",
      "[88,   120] loss: 0.068\n",
      "[88,   160] loss: 0.067\n",
      "[88,   200] loss: 0.074\n",
      "[89,    40] loss: 0.056\n",
      "[89,    80] loss: 0.062\n",
      "[89,   120] loss: 0.057\n",
      "[89,   160] loss: 0.068\n",
      "[89,   200] loss: 0.066\n",
      "[90,    40] loss: 0.058\n",
      "[90,    80] loss: 0.062\n",
      "[90,   120] loss: 0.065\n",
      "[90,   160] loss: 0.074\n",
      "[90,   200] loss: 0.083\n",
      "[91,    40] loss: 0.054\n",
      "[91,    80] loss: 0.060\n",
      "[91,   120] loss: 0.059\n",
      "[91,   160] loss: 0.060\n",
      "[91,   200] loss: 0.062\n",
      "[92,    40] loss: 0.060\n",
      "[92,    80] loss: 0.052\n",
      "[92,   120] loss: 0.051\n",
      "[92,   160] loss: 0.060\n",
      "[92,   200] loss: 0.055\n",
      "[93,    40] loss: 0.050\n",
      "[93,    80] loss: 0.048\n",
      "[93,   120] loss: 0.049\n",
      "[93,   160] loss: 0.060\n",
      "[93,   200] loss: 0.061\n",
      "[94,    40] loss: 0.048\n",
      "[94,    80] loss: 0.055\n",
      "[94,   120] loss: 0.049\n",
      "[94,   160] loss: 0.056\n",
      "[94,   200] loss: 0.058\n",
      "[95,    40] loss: 0.061\n",
      "[95,    80] loss: 0.053\n",
      "[95,   120] loss: 0.053\n",
      "[95,   160] loss: 0.062\n",
      "[95,   200] loss: 0.058\n",
      "[96,    40] loss: 0.057\n",
      "[96,    80] loss: 0.052\n",
      "[96,   120] loss: 0.057\n",
      "[96,   160] loss: 0.061\n",
      "[96,   200] loss: 0.067\n",
      "[97,    40] loss: 0.052\n",
      "[97,    80] loss: 0.053\n",
      "[97,   120] loss: 0.064\n",
      "[97,   160] loss: 0.065\n",
      "[97,   200] loss: 0.060\n",
      "[98,    40] loss: 0.050\n",
      "[98,    80] loss: 0.040\n",
      "[98,   120] loss: 0.047\n",
      "[98,   160] loss: 0.053\n",
      "[98,   200] loss: 0.069\n",
      "[99,    40] loss: 0.071\n",
      "[99,    80] loss: 0.062\n",
      "[99,   120] loss: 0.054\n",
      "[99,   160] loss: 0.047\n",
      "[99,   200] loss: 0.046\n",
      "[100,    40] loss: 0.044\n",
      "[100,    80] loss: 0.051\n",
      "[100,   120] loss: 0.055\n",
      "[100,   160] loss: 0.052\n",
      "[100,   200] loss: 0.049\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 40 == 39:    # print every 40 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 40:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e793ce8f-1811-4ae8-baba-973b2cbdaf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0432a544-7a04-4f4d-a78b-1ca19829be3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca3d96f-bd8e-4eb1-ab42-f4a174ce894a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0482, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
